{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, random, sys\n",
    "from create_datagenerators import create_data_generators\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from data_preprocessing import resize_white, resize_black\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "# from analyse_results import load_image, generate_data_generators\n",
    "# from analyse_results import load_model, print_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model trained on original imgs\n",
    "# RESULTS_FOLDER = \"../saved_models/BEST_OF_THE_BEST/best_orginal_img_alllayers_v3/20190701_1148\"\n",
    "# resize = False\n",
    "\n",
    "# model trained on resized imgs\n",
    "RESULTS_FOLDER = \"../saved_models/BEST_OF_THE_BEST/all_layers_trained_lhcbgpu_inceptionv3_RESIZEDIMGS/20190626_0944\"\n",
    "resize = True\n",
    "\n",
    "# model trained on b&w imgs\n",
    "# RESULTS_FOLDER = \"../saved_models/july_tg/20190731_1323\"\n",
    "# resize = False\n",
    "\n",
    "\n",
    "HYPERPARAMS_FILE =  RESULTS_FOLDER+ '/hyperparams.json'\n",
    "\n",
    "with open(HYPERPARAMS_FILE, \"r\") as read_file:\n",
    "    data = json.load(read_file)\n",
    "\n",
    "HYPERPARAMS = data['hyperparameters'][0]\n",
    "BATCHSIZE = HYPERPARAMS['BATCHSIZE']\n",
    "\n",
    "#20190612_1048\n",
    "if (os.getcwd() == '/home/kalkami/translearn'):\n",
    "    #lhcpgpu1\n",
    "    TRAIN_DIR = '/data/IntelliGate/kalkami/DATASETS/carsStanford_all/train'\n",
    "    TEST_DIR = '/data/IntelliGate/kalkami/DATASETS/carsStanford_all/test'\n",
    "    TRAIN_DIR_TST = TRAIN_DIR\n",
    "    TEST_DIR_TST = TEST_DIR\n",
    "    VALID_DIR_TST = TEST_DIR\n",
    "else:\n",
    "    #local\n",
    "    TRAIN_DIR = '/media/kamila/System/Users/Kama/Documents/DATASETS/carsStanford_all/train'\n",
    "    TEST_DIR = '/media/kamila/System/Users/Kama/Documents/DATASETS/carsStanford_all/test'\n",
    "    TRAIN_DIR_TST = '/media/kamila/System/Users/Kama/Documents/DATASETS/carsStanford_all/train'\n",
    "    TEST_DIR_TST = '/media/kamila/System/Users/Kama/Documents/DATASETS/carsStanford_all_bw/test'\n",
    "    TEST_DIR_TST = '/media/kamila/System/Users/Kama/Documents/DATASETS/carsStanford_all/test'\n",
    "    VALID_DIR_TST = '/media/kamila/System/Users/Kama/Documents/DATASETS/CARS_GOOGLE_IMG/downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path, input_shape, resize = False):\n",
    "    if resize:\n",
    "        img, pth = resize_black(input_shape[1], img_path, print_oldsize=False)\n",
    "    else:\n",
    "        img = image.load_img(img_path, target_size=input_shape)\n",
    "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "    return img_tensor\n",
    "\n",
    "\n",
    "        \n",
    "def generate_data_generators(input_shape):\n",
    "    generator_train, generator_test = create_data_generators(input_shape, BATCHSIZE, \n",
    "                                                                TRAIN_DIR, TEST_DIR, \n",
    "                                                                save_augumented=None, \n",
    "                                                                plot_imgs = False)\n",
    "    return generator_train, generator_test\n",
    "        \n",
    "        \n",
    "def load_model(results_folder):\n",
    "    # load json and create model\n",
    "    json_file = open(results_folder + '/model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(results_folder + \"/weights.best.hdf5\")\n",
    "    input_shape = loaded_model.layers[0].output_shape[1:3]\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model, input_shape\n",
    "\n",
    "\n",
    "\n",
    "def print_confusion_matrix(cls_pred, cls_test, class_names, cmap=plt.cm.Blues):\n",
    "    '''Helper-function for printing confusion matrix'''\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "    # Get the confusion matrix using sklearn.\n",
    "    cm = confusion_matrix(y_true=cls_test,  # True class for test-set.\n",
    "                          y_pred=cls_pred)  # Predicted class.\n",
    "    print(\"Confusion matrix:\")\n",
    "    # Print the confusion matrix as text.\n",
    "    #print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    # Print the class-names for easy reference.\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(\"({0}) {1}\".format(i, class_name))\n",
    "        \n",
    "        \n",
    "# def calc_acc(y_pred, y_test):\n",
    "#     num_corrects = 0\n",
    "#     for i in range(num_samples):\n",
    "#         pred = y_pred[i]\n",
    "#         test = y_test[i]\n",
    "#         if pred == test:\n",
    "#             num_corrects += 1\n",
    "# return num_corrects / num_samples\n",
    "        \n",
    "    \n",
    "        \n",
    "def decode_predictions(preds, class_names, top=5):\n",
    "    results = []\n",
    "    for pred in preds:\n",
    "        top_indices = pred.argsort()[-top:][::-1]\n",
    "        result = [(class_names[i], pred[i]) for i in top_indices]\n",
    "        result.sort(key=lambda x: x[1], reverse=True)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "def predict(img_path, model, input_shape, class_names, correct_class, resize=False, show_imgs=True, top=5):\n",
    "    img_array = load_image(img_path, input_shape, resize = resize)\n",
    "    preds = model.predict(img_array)\n",
    "    predictions = decode_predictions(preds, class_names, top=top)\n",
    "    top1_pred = predictions[0][0]\n",
    "    #print(predictions)\n",
    "    #print(correct_class)\n",
    "    if show_imgs:\n",
    "        img_org = image.load_img(img_path)\n",
    "        fig, axs = plt.subplots(1,2)\n",
    "        axs[0].set_title(correct_class)\n",
    "        axs[0].imshow(img_org)\n",
    "        axs[1].set_title(str(top1_pred))\n",
    "        axs[1].imshow(img_array[0])\n",
    "        plt.show()\n",
    "    return predictions\n",
    "      \n",
    "        \n",
    "\n",
    "##------------------## All above should be transfer to the \"analyse_results.py\"    \n",
    "\n",
    "def show_model_performance(loaded_model, generator_train, generator_test):\n",
    "    steps_test = generator_test.n / BATCHSIZE\n",
    "    steps_train = generator_test.n / BATCHSIZE\n",
    "    cls_train = generator_train.classes\n",
    "    cls_test = generator_test.classes\n",
    "    class_names = list(generator_train.class_indices.keys())\n",
    "    # Predict the classes for all images in the test-set\n",
    "    y_pred = loaded_model.predict_generator(generator_test,\n",
    "                                         steps=steps_test)\n",
    "\n",
    "    # Convert the predicted classes from arrays to integers.\n",
    "    cls_pred = np.argmax(y_pred,axis=1)\n",
    "\n",
    "    # Plot examples of mis-classified images.\n",
    "    # plot_example_errors(cls_pred)\n",
    "    \n",
    "    # Print the confusion matrix.\n",
    "    print_confusion_matrix(cls_pred, cls_test, class_names)\n",
    "    #result = loaded_model.evaluate_generator(generator_test, steps=steps_test)\n",
    "    #result_train = loaded_model.evaluate_generator(generator_train, steps=steps_train)\n",
    "    #print(\"Train-set classification accuracy: {0:.2%}\".format(result_train[1]))\n",
    "    #print(\"Test-set classification accuracy: {0:.2%}\".format(result[1]))\n",
    "        \n",
    "def return_class_names_list(results_folder):\n",
    "    class_names = []\n",
    "    # open file and read the content in a list\n",
    "    with open(results_folder+'/class_names.txt', 'r') as filehandle:  \n",
    "        for line in filehandle:\n",
    "            current_line = line[:-1]\n",
    "            class_names.append(current_line)\n",
    "    return class_names\n",
    "        \n",
    "def perform_pred(loaded_model, resize=False, car_class=None, img_pth=None, show_imgs=True):\n",
    "    test_dir = TEST_DIR_TST\n",
    "    results_folder = RESULTS_FOLDER\n",
    "    \n",
    "    if os.path.exists(results_folder+'/class_names.txt'):\n",
    "        class_names = return_class_names_list(results_folder)\n",
    "\n",
    "    else:\n",
    "        generator_train, generator_test = generate_data_generators(results_folder, input_shape)\n",
    "        class_names = list(generator_train.class_indices.keys())\n",
    "        print(class_names)\n",
    "        with open(results_folder+'/class_names.txt', 'w') as filehandle:  \n",
    "            for listitem in class_names:\n",
    "                filehandle.write('%s\\n' % listitem)\n",
    "                \n",
    "    if car_class is None:\n",
    "        car_class = random.choice(class_names)\n",
    "    \n",
    "    if img_pth is None: \n",
    "        # randomly select an image from defined class     \n",
    "        test_dir_full = test_dir + '/' + car_class\n",
    "        test_img = test_dir_full + '/' + random.choice(os.listdir(test_dir_full))\n",
    "    else:\n",
    "        test_img = img_pth\n",
    "        \n",
    "    \n",
    "    input_shape = loaded_model.layers[0].output_shape[1:3]\n",
    "    \n",
    "          \n",
    "    predictions = predict(test_img, loaded_model, input_shape, class_names, car_class, resize=resize, show_imgs=show_imgs)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model, input_shape=load_model(RESULTS_FOLDER)\n",
    "generator_train, generator_test = generate_data_generators(input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_make_from_classname(class_name):\n",
    "    return class_name.split(' ', 1)[0]\n",
    "\n",
    "\n",
    "def take_cartype_from_classname(class_name):\n",
    "    elements = class_name.split()\n",
    "    if class_name == 'Infiniti G Coupe IPL 2012':\n",
    "        return elements[len(elements)-3]\n",
    "    return elements[len(elements)-2]\n",
    "\n",
    "\n",
    "\n",
    "def return_most_common_brands(class_names):\n",
    "    brands_in_dataset = []\n",
    "    brands_in_dataset_common = []\n",
    "    cnt = Counter()\n",
    "    for class_name in class_names:\n",
    "        brands_in_dataset.append(take_make_from_classname(class_name))\n",
    "\n",
    "    # for brand in Counter.brands_in_dataset:\n",
    "    #     cnt[brand] += 1\n",
    "    brands_in_dataset_common = Counter(brands_in_dataset).most_common(30)\n",
    "    brands_in_dataset_common = [element[0] for element in brands_in_dataset_common]\n",
    "    return brands_in_dataset_common\n",
    "\n",
    "def return_car_types(class_names):\n",
    "    car_types_in_dataset = []\n",
    "    for class_name in class_names:\n",
    "        car_types_in_dataset.append(take_cartype_from_classname(class_name))\n",
    "    car_types_in_dataset_common = Counter(car_types_in_dataset).most_common(9)\n",
    "    car_types_in_dataset_common = [element[0] for element in car_types_in_dataset_common]\n",
    "    return car_types_in_dataset_common\n",
    "\n",
    "def is_popular_brand(class_name, popular_brands):\n",
    "    return take_make_from_classname(class_name) in popular_brands\n",
    "       \n",
    "\n",
    "def is_popular_type(class_name, popular_types):\n",
    "    return take_cartype_from_classname(class_name) in popular_types\n",
    "\n",
    "take_cartype_from_classname('Infiniti G Coupe IPL 2012')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_horizontal_bar(df, title='', fontsize=5, savepath='', many_data=True):\n",
    "    if many_data:\n",
    "        ax = df.plot.barh(color='#86bf91', zorder=2, width=0.85, figsize=(10,25))\n",
    "    else:\n",
    "        ax = df.plot.barh(color='#86bf91', zorder=2, width=0.85)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    plt.ylabel('Odpowiedź sieci', fontsize=12, weight='bold')\n",
    "    plt.xlabel('Wystąpienia', fontsize=12, weight='bold')\n",
    "    plt.title(title, fontsize=14, weight='bold')\n",
    "    if savepath != '':\n",
    "        fig_name = title + '.png'\n",
    "        fig_path = savepath + '/' + fig_name\n",
    "        plt.savefig(fig_path)\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy_for_all_classes(class_and_acc, title='', fontsize=5, savepath='', many_data=False):\n",
    "    labels = list(class_and_acc.keys())\n",
    "    values = list(class_and_acc.values())\n",
    "    indexes = np.arange(len(labels))\n",
    "    df = pd.DataFrame({'x' : labels , 'y' : values})\n",
    "    df = df.sort_values('y',ascending = True)\n",
    "    #df = df2[0:15]\n",
    "    df = pd.DataFrame(list(zip(df['y'], df['x']))).set_index(1)\n",
    "    # ax = df.plot.barh(color='#86bf91', zorder=2, width=0.85, figsize=(10,45))\n",
    "    if many_data:\n",
    "        ax = df.plot.barh(color='#86bf91', zorder=2, width=0.85, figsize=(10,25))\n",
    "    else:\n",
    "        ax = df.plot.barh(color='#86bf91', zorder=2, width=0.85)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    plt.ylabel('Klasy', fontsize=12, weight='bold')\n",
    "    plt.xlabel('Dokładność', fontsize=12, weight='bold')\n",
    "    plt.title(title, fontsize=14, weight='bold')\n",
    "    if savepath != '':\n",
    "        fig_name = title + '.png'\n",
    "        fig_path = savepath + '/' + fig_name\n",
    "        plt.savefig(fig_path)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def mostcommon_predictions(list_of_preds, title='', fontsize=5, savepath='', many_data=True):\n",
    "    cnt = Counter()\n",
    "    for pred in list_of_preds:\n",
    "        cnt[pred] += 1\n",
    "    labels = list(cnt.keys())\n",
    "    values = list(cnt.values())\n",
    "    indexes = np.arange(len(labels))\n",
    "    df = pd.DataFrame({'x' : labels , 'y' : values})\n",
    "    df = df.sort_values('y',ascending = True)\n",
    "    df = pd.DataFrame(list(zip(df['y'], df['x']))).set_index(1)\n",
    "    if many_data:\n",
    "        ax = df.plot.barh(color='#86bf91', zorder=2, width=0.85, figsize=(10,25), fontsize = 16)\n",
    "    else:\n",
    "        ax = df.plot.barh(color='#86bf91', zorder=2, width=0.85, fontsize = 16)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    plt.ylabel('Odpowiedź sieci', fontsize=16, weight='bold')\n",
    "    plt.xlabel('Wystąpienia', fontsize=16, weight='bold')\n",
    "    plt.title(title, fontsize=14, weight='bold')\n",
    "    if savepath != '':\n",
    "        fig_name = title + '.png'\n",
    "        fig_path = savepath + '/' + fig_name\n",
    "        plt.savefig(fig_path)\n",
    "    plt.show()\n",
    "    return cnt\n",
    "\n",
    "# # -*- coding: UTF-8 -*-\n",
    "# import matplotlib.pyplot as plt\n",
    "# # The slices will be ordered and plotted counter-clockwise.\n",
    "# labels = [r'Rayos X (88.4 %)', r'RMN en solucion (10.6 %)', \n",
    "# r'Microscopia electronica (0.7 %)', r'Otros (0.3 %)']\n",
    "# sizes = [88.4, 10.6, 0.7, 0.3]\n",
    "# colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n",
    "# patches, texts = plt.pie(sizes, colors=colors, startangle=90)\n",
    "# plt.legend(patches, labels, loc=\"best\")\n",
    "# # Set aspect ratio to be equal so that pie is drawn as a circle.\n",
    "# plt.axis('equal')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "def plot_prediction_analysis_all(metrics):\n",
    "    full_correct = metrics[0]\n",
    "    correct_only_brand_or_type = metrics[2]\n",
    "    full_incorrect = metrics[3]\n",
    "    # Data to plot\n",
    "    labels = 'Niepoprawne wskazania', 'Poprawne wskazania', 'Niepoprawne wskazania - ale zgadza się marka lub typ'\n",
    "    sizes = [full_incorrect, full_correct, correct_only_brand_or_type]\n",
    "    colors = ['yellowgreen', 'lightcoral', 'lightskyblue']\n",
    "    explode = (0, 0.1, 0)  # explode 1st slice\n",
    "    # Plot\n",
    "    patches = plt.pie(sizes, explode=explode, colors=colors,\n",
    "            autopct='%1.1f%%', shadow=True, startangle=160)\n",
    "    plt.legend(patches[0], labels, loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_prediction_analysis_brand(metrics):\n",
    "    correct_brand = metrics[0] + metrics[1] # correct brand, doesn't matter if model\n",
    "    incorrect_brand = (sum(metrics) - metrics[1]) - correct_brand\n",
    "    # Data to plot\n",
    "    labels = 'Prawidłowa marka', 'Nieprawidłowa marka'\n",
    "    sizes = [correct_brand, incorrect_brand]\n",
    "    colors = ['gold', 'lightskyblue']\n",
    "    explode = (0.1, 0)  # explode 1st slice\n",
    "    # Plot\n",
    "    patches = plt.pie(sizes, explode=explode, colors=colors,\n",
    "            autopct='%1.1f%%', shadow=True, startangle=160)\n",
    "    plt.legend(patches[0], labels, loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    \n",
    "#plot_prediction_analysis_all([30,13,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(img_path, model, input_shape, class_names, input_shape, class_names, correct_class, show_imgs=True, top=5):\n",
    "class_names = return_class_names_list(RESULTS_FOLDER)\n",
    "common_brands = return_most_common_brands(class_names)\n",
    "common_types = return_car_types(class_names)\n",
    "#resize = False\n",
    "# print(common_brands)\n",
    "# print(common_types)\n",
    "\n",
    "\n",
    "def predict_on_class(model, input_shape, class_names, \n",
    "                     common_brands, common_types, folder_path, resize=False, threshold=0.9999, \n",
    "                     show_plots=True, print_analysis=True, savepath=''):\n",
    "    \n",
    "    class_name = os.path.basename(folder_path)\n",
    "#     print('\\n\\n')\n",
    "#     printmd('**'+class_name+'**')\n",
    "    class_name_brand = take_make_from_classname(class_name)\n",
    "    class_name_cartype = take_cartype_from_classname(class_name)\n",
    "#     print(\"Brand:\", class_name_brand)\n",
    "#     print(\"Type:\", class_name_cartype)\n",
    "#     print('\\n')\n",
    "    # verify popularity ===> boolean popular_cartype_or_brand = False\n",
    "    n_correct_brand = None\n",
    "    n_correct_brand_or_type = None # correct brand, but not necesserely model (fiat punto instead of fiat bravo)\n",
    "    n_correct_type = None\n",
    "    n_totally_incorrect = None\n",
    "    \n",
    "    \n",
    "    if is_popular_brand(class_name, common_brands):\n",
    "        n_correct_brand = 0\n",
    "        n_correct_brand_or_type = 0\n",
    "        n_totally_incorrect = 0\n",
    "    else:\n",
    "        print (\"The brand of car is not a popular brand. Statistics concerning brand won't be provided.\")\n",
    "    if is_popular_type(class_name, common_types):\n",
    "        n_correct_brand_or_type = 0\n",
    "        n_totally_incorrect = 0\n",
    "    else:\n",
    "        print (\"The type of car is not a popular type. Statistics concerning type won't be provided.\")\n",
    "\n",
    "    \n",
    "    main_return_dict = {}\n",
    "    n_correct_make_and_model = 0 # correctly predicted (the higher value the better)\n",
    "    n_corrects_high_confidence = 0 # correctly predicted with high confidence (>= threshold) (higher = better)\n",
    "    n_incorrect_high_confidence = 0 # predicted incorrectly but with hight confidence (lowet = better)\n",
    "    n_all_samples = 0 # all test/valid samples\n",
    "    # all vars below concerns only the first prediction\n",
    "\n",
    "    #n_correct_brand = 0 # all correctly predicted brand: bmw, fiat, volvo etc \n",
    "    #n_correct_type = 0 # wagon, hatchback, sedan etc (correct type but not necesserely make&model) (higher = better)\n",
    "    incorrect_predictions_high_confidence = [] # concerns only first prediction (top1)\n",
    "    incorrect_predictions = [] # concerns only first prediction (top1)\n",
    "    all_top1_predictions = []\n",
    "    top5accuracy = 0\n",
    "    \n",
    "    # list for further analysis\n",
    "    top5_predictions = [] # all top 5 pred for all samples without their confidences into list\n",
    "    top5_predictions_high = [] # top 5 pred for all samples into list only with conf higher than 0.3\n",
    "    \n",
    "    # 3-5 NAJCZESCIEJ ZGADYWANE MARKI DLA MODELU\n",
    "    # WYKRES TO POWYŻSZE PRZEDSTAWIAJĄCY\n",
    "    for img in os.scandir(folder_path):\n",
    "        n_all_samples+=1\n",
    "        predictions = predict(os.path.abspath(img), model, input_shape, class_names, class_name, resize=resize, top=1, show_imgs=False)\n",
    "        all_top1_predictions.append(predictions[0][0][0])\n",
    "        if (predictions[0][0][0] == class_name):\n",
    "            n_correct_make_and_model+=1\n",
    "            if (float(predictions[0][0][1]) >= threshold):\n",
    "                n_corrects_high_confidence+=1\n",
    "        else:\n",
    "            incorrect_predictions.append(predictions[0][0][0])\n",
    "            if (float(predictions[0][0][1]) >= threshold):\n",
    "                n_incorrect_high_confidence+=1\n",
    "            if n_correct_brand is not None:\n",
    "                if take_make_from_classname(predictions[0][0][0]) == class_name_brand:\n",
    "                    n_correct_brand+=1\n",
    "                    n_correct_brand_or_type+=1\n",
    "                    #print(predictions[0][0][0])\n",
    "                else:\n",
    "                    if (n_correct_brand_or_type is not None) and (\n",
    "                                                                take_cartype_from_classname(\n",
    "                                                                predictions[0][0][0]) == class_name_cartype):\n",
    "                        #print(predictions[0][0][0])\n",
    "                        n_correct_brand_or_type+=1\n",
    "            else:\n",
    "                if (n_correct_brand_or_type is not None) and (\n",
    "                                                                take_cartype_from_classname(\n",
    "                                                                predictions[0][0][0]) == class_name_cartype):\n",
    "                    #print(predictions[0][0][0])\n",
    "                    n_correct_brand_or_type+=1\n",
    "                        \n",
    "        if n_correct_brand_or_type is not None:\n",
    "            n_totally_incorrect = len(incorrect_predictions) - n_correct_brand_or_type\n",
    "        else:\n",
    "            n_correct_brand_or_type = len(incorrect_predictions)\n",
    "            \n",
    "#         for prediction in predictions[0]:\n",
    "#             top5_predictions.append(prediction[0])\n",
    "#             if (float(prediction[1]) >= 0.3):\n",
    "#                 top5_predictions_high.append(prediction[0])\n",
    "            # print(prediction[0])\n",
    "    #print(top5_predictions)\n",
    "    #print(incorrect_predictions)\n",
    "    accuracy = n_correct_make_and_model/n_all_samples*100\n",
    "    correctly_pred_high_conf_perc = n_corrects_high_confidence/n_all_samples*100\n",
    "    incorrectly_pred_hih_conf_perc = n_incorrect_high_confidence/n_all_samples*100\n",
    "    brand_type_analysis = [n_correct_make_and_model, \n",
    "                           n_correct_brand, n_correct_brand_or_type, n_totally_incorrect]\n",
    "    \n",
    "    #print(brand_type_analysis)\n",
    "    if print_analysis:\n",
    "        print(\"All samples: {}. Correctly predicted: {}. Accuracy: {}%.\".format(n_all_samples,\n",
    "                    n_correct_make_and_model,accuracy))\n",
    "        print(\"Correctly predicted with high confidence: {} => {}% of all.\".\n",
    "              format(n_corrects_high_confidence,correctly_pred_high_conf_perc))\n",
    "        print(\"Incorrectly predicted with high confidence: {} => {}% of all. \".\n",
    "              format(n_incorrect_high_confidence,incorrectly_pred_hih_conf_perc))\n",
    "        #print(brand_type_analysis)\n",
    "    \n",
    "    if show_plots:\n",
    "        #mostcommon_predictions(top5_predictions, class_name+': '+'Most common top5 predictions',\n",
    "                               #savepath=savepath)\n",
    "\n",
    "        if n_correct_brand is not None:\n",
    "            plot_prediction_analysis_all(brand_type_analysis)\n",
    "            plot_prediction_analysis_brand(brand_type_analysis)\n",
    "        else:\n",
    "            if n_correct_brand_or_type is not None:\n",
    "                plot_prediction_analysis_all(brand_type_analysis)\n",
    "        \n",
    "        mostcommon_predictions(all_top1_predictions, \n",
    "                                    class_name, many_data=False,\n",
    "                                    savepath=savepath)\n",
    "    \n",
    "    #testing treashold\n",
    "#     if (incorrectly_pred_hih_conf_perc > 0.0):\n",
    "#         print(class_name + \"\\t\" + str(incorrectly_pred_hih_conf_perc))\n",
    "        \n",
    "    return accuracy, correctly_pred_high_conf_perc, incorrectly_pred_hih_conf_perc, brand_type_analysis\n",
    "\n",
    "# plot_model(loaded_model, to_file='model.svg', show_layr_names=True, show_shapes=True)\n",
    "predict_on_class(loaded_model, input_shape, \n",
    "                 class_names, common_brands, common_types, \n",
    "                 TEST_DIR_TST + '/BMW ActiveHybrid 5 Sedan 2012', resize=resize, show_plots=True, print_analysis=False)\n",
    "\n",
    "# predict_on_class(loaded_model, input_shape, \n",
    "#                  class_names, common_brands, common_types, \n",
    "#                  TEST_DIR_TST + '/Dodge Caliber Wagon 2012')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "\n",
    "class_names = return_class_names_list(RESULTS_FOLDER)\n",
    "common_brands = return_most_common_brands(class_names)\n",
    "common_types = return_car_types(class_names)\n",
    "\n",
    "def create_folder_with_analysis(results_folder):\n",
    "    # name of dir\n",
    "    ANALYSIS_PATH = \"../saved_models/\" + results_folder + \"/resuls_analysis\"\n",
    "    access_rights = 0o755\n",
    "    try:  \n",
    "        os.makedirs(ANALYSIS_PATH, access_rights)\n",
    "    except OSError:  \n",
    "        print (\"Creation of the directory %s failed\" % ANALYSIS_PATH)\n",
    "    else:  \n",
    "        print (\"Successfully created the directory %s\" % ANALYSIS_PATH)\n",
    "    return ANALYSIS_PATH\n",
    "\n",
    "def analyse_all_classes(loaded_model, results_folder, test_directory, resize=False):\n",
    "    # create target folder\n",
    "    ANALYSIS_PATH = create_folder_with_analysis(results_folder)\n",
    "    general_acc_dict = {}\n",
    "    incorrect_high_conf = {}\n",
    "    brand_type_analysis_counter = [0,0,0,0]\n",
    "    brand_analysis_counter = [0,0,0,0]\n",
    "    if os.path.exists(ANALYSIS_PATH):\n",
    "        for subfolder in os.scandir(test_directory):\n",
    "            class_name_path = os.path.abspath(subfolder)\n",
    "            results_for_class=predict_on_class(loaded_model, input_shape, class_names, \n",
    "                                                    common_brands, common_types, \n",
    "                                                    class_name_path, resize=resize, threshold=0.9999, \n",
    "                                                    print_analysis=False, show_plots=False, \n",
    "                                                    savepath=ANALYSIS_PATH)\n",
    "            brand_type_an_oneclass = results_for_class[3]\n",
    "\n",
    "            if brand_type_an_oneclass[1] is not None:\n",
    "                for n in range(0,4):\n",
    "                    brand_analysis_counter[n] = brand_analysis_counter[n] + brand_type_an_oneclass[n]\n",
    "                    brand_type_analysis_counter[n] = brand_type_analysis_counter[n] + brand_type_an_oneclass[n]\n",
    "            elif brand_type_an_oneclass[1] is None and brand_type_an_oneclass[2] is not None:\n",
    "                for n in range(0,4):\n",
    "                    if n != 1:\n",
    "                        brand_type_analysis_counter[n] = brand_type_analysis_counter[n] + brand_type_an_oneclass[n]\n",
    "            else:\n",
    "                continue\n",
    "            general_acc_dict[subfolder.name] = results_for_class[0]\n",
    "            incorrect_high_conf[subfolder.name] = results_for_class[2]\n",
    "#     # plot overall analysis of general accuracy\n",
    "#     plot_accuracy_for_all_classes(general_acc_dict, title='Dokładność odpowiedzi sieci dla poszczególnych klas', \n",
    "#                                   fontsize=5, savepath='', many_data=False)\n",
    "    # plot overall analysis of general accuracy for 15 best recognizable cars\n",
    "    sorted_general_acc_dict = sorted(general_acc_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    sorted_general_acc_Dict = collections.OrderedDict(sorted_general_acc_dict)\n",
    "#     print(sorted_general_acc_Dict)\n",
    "    sorted_general_acc_Dict_sliced = dict(itertools.islice(sorted_general_acc_Dict.items(), 15))\n",
    "    plot_accuracy_for_all_classes(sorted_general_acc_Dict_sliced, title='Dokładność odpowiedzi sieci dla poszczególnych klas', \n",
    "                                  fontsize=5, savepath='', many_data=False)\n",
    "    # plot overall analysis of incorrectly predicted\n",
    "#     plot_accuracy_for_all_classes(incorrect_high_conf, \n",
    "#                                   title='Incorrect predictions with confidence', \n",
    "#                                   fontsize=5, savepath='', many_data=True)\n",
    "    # plot overall analysis of correctly/incorrectly predicted due to brand\n",
    "#     print(brand_analysis_counter)\n",
    "    plot_prediction_analysis_brand(brand_analysis_counter)\n",
    "    # plot overall analysis of correctly pred/correctly brand/cartype\n",
    "    plot_prediction_analysis_all(brand_type_analysis_counter)\n",
    "\n",
    "#TEST_DIR_TST = '/media/kamila/System/Users/Kama/Documents/DATASETS/carsStanford_s/test'\n",
    "analyse_all_classes(loaded_model, RESULTS_FOLDER,TEST_DIR_TST, resize=resize)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplenv",
   "language": "python",
   "name": "deeplenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
